{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAGGLE TITANIC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johansson, Mr. Erik</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350052</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Backstrom, Mrs. Karl Alfred (Maria Mathilda Gu...</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3101278</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Sigrid Elisabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>703</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Barbara, Miss. Saiide</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2691</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "395          396         0       3   \n",
       "85            86         1       3   \n",
       "201          202         0       3   \n",
       "542          543         0       3   \n",
       "702          703         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "395                                Johansson, Mr. Erik    male  22.0      0   \n",
       "85   Backstrom, Mrs. Karl Alfred (Maria Mathilda Gu...  female  33.0      3   \n",
       "201                                Sage, Mr. Frederick    male   NaN      8   \n",
       "542                  Andersson, Miss. Sigrid Elisabeth  female  11.0      4   \n",
       "702                              Barbara, Miss. Saiide  female  18.0      0   \n",
       "\n",
       "     Parch    Ticket     Fare Cabin Embarked  \n",
       "395      0    350052   7.7958   NaN        S  \n",
       "85       0   3101278  15.8500   NaN        S  \n",
       "201      2  CA. 2343  69.5500   NaN        S  \n",
       "542      2    347082  31.2750   NaN        S  \n",
       "702      1      2691  14.4542   NaN        C  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train=pd.read_csv(\"data/train.csv\")\n",
    "data_train=shuffle(data_train,random_state=3)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['A10', 'A14', 'A16', 'A19', 'A20', 'A23', 'A24', 'A26', 'A31',\n",
       "        'A32', 'A34', 'A36', 'A5', 'A6', 'A7', 'B101', 'B102', 'B18',\n",
       "        'B19', 'B20', 'B22', 'B28', 'B3', 'B30', 'B35', 'B37', 'B38',\n",
       "        'B39', 'B4', 'B41', 'B42', 'B49', 'B5', 'B50', 'B51 B53 B55',\n",
       "        'B57 B59 B63 B66', 'B58 B60', 'B69', 'B71', 'B73', 'B77', 'B78',\n",
       "        'B79', 'B80', 'B82 B84', 'B86', 'B94', 'B96 B98', 'C101', 'C103',\n",
       "        'C104', 'C106', 'C110', 'C111', 'C118', 'C123', 'C124', 'C125',\n",
       "        'C126', 'C128', 'C148', 'C2', 'C22 C26', 'C23 C25 C27', 'C30',\n",
       "        'C32', 'C45', 'C46', 'C47', 'C49', 'C50', 'C52', 'C54', 'C62 C64',\n",
       "        'C65', 'C68', 'C7', 'C70', 'C78', 'C82', 'C83', 'C85', 'C86',\n",
       "        'C87', 'C90', 'C91', 'C92', 'C93', 'C95', 'C99', 'D', 'D10 D12',\n",
       "        'D11', 'D15', 'D17', 'D19', 'D20', 'D21', 'D26', 'D28', 'D30',\n",
       "        'D33', 'D35', 'D36', 'D37', 'D45', 'D46', 'D47', 'D48', 'D49',\n",
       "        'D50', 'D56', 'D6', 'D7', 'D9', 'E10', 'E101', 'E12', 'E121',\n",
       "        'E17', 'E24', 'E25', 'E31', 'E33', 'E34', 'E36', 'E38', 'E40',\n",
       "        'E44', 'E46', 'E49', 'E50', 'E58', 'E63', 'E67', 'E68', 'E77',\n",
       "        'E8', 'F E69', 'F G63', 'F G73', 'F2', 'F33', 'F38', 'F4', 'G6',\n",
       "        'T', nan], dtype=object)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin=data_train[['Cabin']]\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder=OrdinalEncoder()\n",
    "cabin_encoded=ordinal_encoder.fit_transform(cabin)\n",
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[['Cabin']]=cabin_encoded\n",
    "train_labels=data_train[\"Survived\"]\n",
    "data_train.loc[data_train['Sex'] =='male','s'] = 1 \n",
    "data_train.loc[data_train['Sex'] =='female','s'] = 0\n",
    "data_train=data_train.drop(['PassengerId','Name','Ticket','Embarked','Sex','Survived'],axis=1)\n",
    "data_train.to_numpy()\n",
    "data_train=np.nan_to_num(data_train)\n",
    "train_labels.to_numpy()\n",
    "train_examples=data_train\n",
    "X = train_examples\n",
    "y = train_labels\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "BATCH_SIZE = int((X_train.shape[0])/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TORCH IMPLEMENTATION BEGINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_test= sc.fit_transform(X_test)\n",
    "y_train=pd.Series.to_numpy(y_train)\n",
    "y_test=pd.Series.to_numpy(y_test)\n",
    "\n",
    "X_train=torch.from_numpy(X_train)\n",
    "X_test=torch.from_numpy(X_test)\n",
    "y_train=torch.from_numpy(y_train)\n",
    "y_test=torch.from_numpy(y_test)\n",
    "y_train = y_train.view(y_train.shape[0],1)\n",
    "y_test = y_test.view(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_samples,features)=X_train.shape\n",
    "input_size=features\n",
    "output_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training(nn.Module):\n",
    "\n",
    "    def __init__(self,input):\n",
    "        super(training,self).__init__()\n",
    "\n",
    "        self.lin1=nn.Linear(input,input)\n",
    "        self.lin2=nn.Linear(input,14)\n",
    "        self.lin3=nn.Linear(14,7)\n",
    "        self.lin4=nn.Linear(7,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.lin1(x))\n",
    "        x=torch.relu(self.lin2(x))\n",
    "        x=torch.relu(self.lin3(x))\n",
    "        return torch.sigmoid(self.lin4(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([712, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.6767 \n",
      "epoch 101, loss 0.6701 \n",
      "epoch 201, loss 0.6671 \n",
      "epoch 301, loss 0.6651 \n",
      "epoch 401, loss 0.6633 \n",
      "epoch 501, loss 0.6613 \n",
      "epoch 601, loss 0.6591 \n",
      "epoch 701, loss 0.6566 \n",
      "epoch 801, loss 0.6534 \n",
      "epoch 901, loss 0.6495 \n",
      "epoch 1001, loss 0.6443 \n",
      "epoch 1101, loss 0.6374 \n",
      "epoch 1201, loss 0.6282 \n",
      "epoch 1301, loss 0.6156 \n",
      "epoch 1401, loss 0.5984 \n",
      "epoch 1501, loss 0.5755 \n",
      "epoch 1601, loss 0.5467 \n",
      "epoch 1701, loss 0.5152 \n",
      "epoch 1801, loss 0.4871 \n",
      "epoch 1901, loss 0.4672 \n",
      "epoch 2001, loss 0.4552 \n",
      "epoch 2101, loss 0.4479 \n",
      "epoch 2201, loss 0.4434 \n",
      "epoch 2301, loss 0.4403 \n",
      "epoch 2401, loss 0.4381 \n",
      "epoch 2501, loss 0.4365 \n",
      "epoch 2601, loss 0.4352 \n",
      "epoch 2701, loss 0.4341 \n",
      "epoch 2801, loss 0.4332 \n",
      "epoch 2901, loss 0.4325 \n",
      "epoch 3001, loss 0.4319 \n",
      "epoch 3101, loss 0.4313 \n",
      "epoch 3201, loss 0.4307 \n",
      "epoch 3301, loss 0.4302 \n",
      "epoch 3401, loss 0.4298 \n",
      "epoch 3501, loss 0.4293 \n",
      "epoch 3601, loss 0.4289 \n",
      "epoch 3701, loss 0.4285 \n",
      "epoch 3801, loss 0.4281 \n",
      "epoch 3901, loss 0.4278 \n",
      "epoch 4001, loss 0.4275 \n",
      "epoch 4101, loss 0.4272 \n",
      "epoch 4201, loss 0.4269 \n",
      "epoch 4301, loss 0.4266 \n",
      "epoch 4401, loss 0.4262 \n",
      "epoch 4501, loss 0.4259 \n",
      "epoch 4601, loss 0.4256 \n",
      "epoch 4701, loss 0.4253 \n",
      "epoch 4801, loss 0.4250 \n",
      "epoch 4901, loss 0.4246 \n",
      "epoch 5001, loss 0.4242 \n",
      "epoch 5101, loss 0.4239 \n",
      "epoch 5201, loss 0.4235 \n",
      "epoch 5301, loss 0.4231 \n",
      "epoch 5401, loss 0.4227 \n",
      "epoch 5501, loss 0.4223 \n",
      "epoch 5601, loss 0.4219 \n",
      "epoch 5701, loss 0.4215 \n",
      "epoch 5801, loss 0.4211 \n",
      "epoch 5901, loss 0.4207 \n",
      "epoch 6001, loss 0.4203 \n",
      "epoch 6101, loss 0.4198 \n",
      "epoch 6201, loss 0.4194 \n",
      "epoch 6301, loss 0.4189 \n",
      "epoch 6401, loss 0.4185 \n",
      "epoch 6501, loss 0.4180 \n",
      "epoch 6601, loss 0.4176 \n",
      "epoch 6701, loss 0.4171 \n",
      "epoch 6801, loss 0.4167 \n",
      "epoch 6901, loss 0.4162 \n",
      "epoch 7001, loss 0.4158 \n",
      "epoch 7101, loss 0.4153 \n",
      "epoch 7201, loss 0.4148 \n",
      "epoch 7301, loss 0.4143 \n",
      "epoch 7401, loss 0.4136 \n",
      "epoch 7501, loss 0.4130 \n",
      "epoch 7601, loss 0.4124 \n",
      "epoch 7701, loss 0.4118 \n",
      "epoch 7801, loss 0.4114 \n",
      "epoch 7901, loss 0.4109 \n",
      "epoch 8001, loss 0.4105 \n",
      "epoch 8101, loss 0.4100 \n",
      "epoch 8201, loss 0.4095 \n",
      "epoch 8301, loss 0.4091 \n",
      "epoch 8401, loss 0.4086 \n",
      "epoch 8501, loss 0.4080 \n",
      "epoch 8601, loss 0.4075 \n",
      "epoch 8701, loss 0.4069 \n",
      "epoch 8801, loss 0.4064 \n",
      "epoch 8901, loss 0.4059 \n",
      "epoch 9001, loss 0.4053 \n",
      "epoch 9101, loss 0.4046 \n",
      "epoch 9201, loss 0.4040 \n",
      "epoch 9301, loss 0.4033 \n",
      "epoch 9401, loss 0.4027 \n",
      "epoch 9501, loss 0.4020 \n",
      "epoch 9601, loss 0.4014 \n",
      "epoch 9701, loss 0.4007 \n",
      "epoch 9801, loss 0.4000 \n",
      "epoch 9901, loss 0.3994 \n",
      "epoch 10001, loss 0.3988 \n",
      "epoch 10101, loss 0.3982 \n",
      "epoch 10201, loss 0.3977 \n",
      "epoch 10301, loss 0.3971 \n",
      "epoch 10401, loss 0.3966 \n",
      "epoch 10501, loss 0.3961 \n",
      "epoch 10601, loss 0.3956 \n",
      "epoch 10701, loss 0.3951 \n",
      "epoch 10801, loss 0.3947 \n",
      "epoch 10901, loss 0.3942 \n",
      "epoch 11001, loss 0.3938 \n",
      "epoch 11101, loss 0.3934 \n",
      "epoch 11201, loss 0.3929 \n",
      "epoch 11301, loss 0.3925 \n",
      "epoch 11401, loss 0.3920 \n",
      "epoch 11501, loss 0.3916 \n",
      "epoch 11601, loss 0.3912 \n",
      "epoch 11701, loss 0.3907 \n",
      "epoch 11801, loss 0.3902 \n",
      "epoch 11901, loss 0.3898 \n",
      "epoch 12001, loss 0.3894 \n",
      "epoch 12101, loss 0.3891 \n",
      "epoch 12201, loss 0.3887 \n",
      "epoch 12301, loss 0.3883 \n",
      "epoch 12401, loss 0.3879 \n",
      "epoch 12501, loss 0.3875 \n",
      "epoch 12601, loss 0.3872 \n",
      "epoch 12701, loss 0.3869 \n",
      "epoch 12801, loss 0.3865 \n",
      "epoch 12901, loss 0.3862 \n",
      "epoch 13001, loss 0.3858 \n",
      "epoch 13101, loss 0.3854 \n",
      "epoch 13201, loss 0.3851 \n",
      "epoch 13301, loss 0.3847 \n",
      "epoch 13401, loss 0.3842 \n",
      "epoch 13501, loss 0.3837 \n",
      "epoch 13601, loss 0.3833 \n",
      "epoch 13701, loss 0.3828 \n",
      "epoch 13801, loss 0.3822 \n",
      "epoch 13901, loss 0.3817 \n",
      "epoch 14001, loss 0.3812 \n",
      "epoch 14101, loss 0.3806 \n",
      "epoch 14201, loss 0.3801 \n",
      "epoch 14301, loss 0.3796 \n",
      "epoch 14401, loss 0.3791 \n",
      "epoch 14501, loss 0.3785 \n",
      "epoch 14601, loss 0.3780 \n",
      "epoch 14701, loss 0.3775 \n",
      "epoch 14801, loss 0.3770 \n",
      "epoch 14901, loss 0.3765 \n",
      "epoch 15001, loss 0.3760 \n",
      "epoch 15101, loss 0.3756 \n",
      "epoch 15201, loss 0.3751 \n",
      "epoch 15301, loss 0.3747 \n",
      "epoch 15401, loss 0.3743 \n",
      "epoch 15501, loss 0.3739 \n",
      "epoch 15601, loss 0.3736 \n",
      "epoch 15701, loss 0.3733 \n",
      "epoch 15801, loss 0.3730 \n",
      "epoch 15901, loss 0.3726 \n",
      "epoch 16001, loss 0.3722 \n",
      "epoch 16101, loss 0.3719 \n",
      "epoch 16201, loss 0.3716 \n",
      "epoch 16301, loss 0.3713 \n",
      "epoch 16401, loss 0.3709 \n",
      "epoch 16501, loss 0.3706 \n",
      "epoch 16601, loss 0.3703 \n",
      "epoch 16701, loss 0.3700 \n",
      "epoch 16801, loss 0.3698 \n",
      "epoch 16901, loss 0.3695 \n",
      "epoch 17001, loss 0.3693 \n",
      "epoch 17101, loss 0.3691 \n",
      "epoch 17201, loss 0.3689 \n",
      "epoch 17301, loss 0.3687 \n",
      "epoch 17401, loss 0.3685 \n",
      "epoch 17501, loss 0.3682 \n",
      "epoch 17601, loss 0.3680 \n",
      "epoch 17701, loss 0.3678 \n",
      "epoch 17801, loss 0.3676 \n",
      "epoch 17901, loss 0.3675 \n",
      "epoch 18001, loss 0.3673 \n",
      "epoch 18101, loss 0.3670 \n",
      "epoch 18201, loss 0.3667 \n",
      "epoch 18301, loss 0.3665 \n",
      "epoch 18401, loss 0.3664 \n",
      "epoch 18501, loss 0.3662 \n",
      "epoch 18601, loss 0.3661 \n",
      "epoch 18701, loss 0.3659 \n",
      "epoch 18801, loss 0.3657 \n",
      "epoch 18901, loss 0.3656 \n",
      "epoch 19001, loss 0.3654 \n",
      "epoch 19101, loss 0.3653 \n",
      "epoch 19201, loss 0.3652 \n",
      "epoch 19301, loss 0.3651 \n",
      "epoch 19401, loss 0.3649 \n",
      "epoch 19501, loss 0.3648 \n",
      "epoch 19601, loss 0.3647 \n",
      "epoch 19701, loss 0.3646 \n",
      "epoch 19801, loss 0.3645 \n",
      "epoch 19901, loss 0.3643 \n",
      "epoch 20001, loss 0.3642 \n",
      "epoch 20101, loss 0.3640 \n",
      "epoch 20201, loss 0.3638 \n",
      "epoch 20301, loss 0.3637 \n",
      "epoch 20401, loss 0.3635 \n",
      "epoch 20501, loss 0.3634 \n",
      "epoch 20601, loss 0.3632 \n",
      "epoch 20701, loss 0.3631 \n",
      "epoch 20801, loss 0.3629 \n",
      "epoch 20901, loss 0.3627 \n",
      "epoch 21001, loss 0.3626 \n",
      "epoch 21101, loss 0.3625 \n",
      "epoch 21201, loss 0.3623 \n",
      "epoch 21301, loss 0.3622 \n",
      "epoch 21401, loss 0.3621 \n",
      "epoch 21501, loss 0.3620 \n",
      "epoch 21601, loss 0.3618 \n",
      "epoch 21701, loss 0.3617 \n",
      "epoch 21801, loss 0.3616 \n",
      "epoch 21901, loss 0.3615 \n",
      "epoch 22001, loss 0.3614 \n",
      "epoch 22101, loss 0.3612 \n",
      "epoch 22201, loss 0.3611 \n",
      "epoch 22301, loss 0.3609 \n",
      "epoch 22401, loss 0.3607 \n",
      "epoch 22501, loss 0.3605 \n",
      "epoch 22601, loss 0.3603 \n",
      "epoch 22701, loss 0.3600 \n",
      "epoch 22801, loss 0.3598 \n",
      "epoch 22901, loss 0.3596 \n",
      "epoch 23001, loss 0.3593 \n",
      "epoch 23101, loss 0.3590 \n",
      "epoch 23201, loss 0.3588 \n",
      "epoch 23301, loss 0.3586 \n",
      "epoch 23401, loss 0.3584 \n",
      "epoch 23501, loss 0.3581 \n",
      "epoch 23601, loss 0.3577 \n",
      "epoch 23701, loss 0.3573 \n",
      "epoch 23801, loss 0.3570 \n",
      "epoch 23901, loss 0.3567 \n",
      "epoch 24001, loss 0.3565 \n",
      "epoch 24101, loss 0.3562 \n",
      "epoch 24201, loss 0.3560 \n",
      "epoch 24301, loss 0.3557 \n",
      "epoch 24401, loss 0.3555 \n",
      "epoch 24501, loss 0.3553 \n",
      "epoch 24601, loss 0.3552 \n",
      "epoch 24701, loss 0.3550 \n",
      "epoch 24801, loss 0.3548 \n",
      "epoch 24901, loss 0.3547 \n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "num_epochs=25000\n",
    "for epochs in range(num_epochs):\n",
    "    y_pred=model(X_train.float())\n",
    "    loss=criterion(y_pred.float(),y_train.float())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if(epochs%100 == 0):\n",
    "        print(f'epoch {epochs+1}, loss {loss.item():.4f} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.800 \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_predicted=model(X_test.float())\n",
    "    y_predicted_cls= y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'Accuracy : {acc:.3f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CSV SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Cabin    s\n",
       "0       3  34.5      0      0   7.8292    NaN  1.0\n",
       "1       3  47.0      1      0   7.0000    NaN  0.0\n",
       "2       2  62.0      0      0   9.6875    NaN  1.0\n",
       "3       3  27.0      0      0   8.6625    NaN  1.0\n",
       "4       3  22.0      1      1  12.2875    NaN  0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"data/test.csv\")\n",
    "test_id=test[\"PassengerId\"]\n",
    "test.loc[test['Sex'] =='male','s'] = 1 \n",
    "test.loc[test['Sex'] =='female','s'] = 0\n",
    "cabin=test[['Cabin']]\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder=OrdinalEncoder()\n",
    "cabin_encoded=ordinal_encoder.fit_transform(cabin)\n",
    "test[['Cabin']]=cabin_encoded\n",
    "test=test.drop(['Name','Ticket','Embarked','Sex','PassengerId'],axis=1)\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_numpy()\n",
    "test=np.nan_to_num(test)\n",
    "test=torch.from_numpy(test)\n",
    "with torch.no_grad():\n",
    "    ans=model(test.float())\n",
    "    ans= ans.round()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "data.insert(0,\"PassengerId\",test_id)\n",
    "data.insert(1,\"Survived\",ans.int())\n",
    "data.to_csv(\"data/model1_titanic.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47c3d642174270f224528408ce260e326450f5d01584567606deb2c7196ef238"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
