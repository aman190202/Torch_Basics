{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y = torch.tensor([9,18,27,36],dtype=torch.float32)\n",
    "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "learning_rate=0.01\n",
    "n_iters=100\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w],lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, w : 1.350 and loss : 607.50000 \n",
      "Epoch 2, w : 2.497 and loss : 438.91876 \n",
      "Epoch 3, w : 3.473 and loss : 317.11880 \n",
      "Epoch 4, w : 4.302 and loss : 229.11832 \n",
      "Epoch 5, w : 5.007 and loss : 165.53799 \n",
      "Epoch 6, w : 5.606 and loss : 119.60119 \n",
      "Epoch 7, w : 6.115 and loss : 86.41185 \n",
      "Epoch 8, w : 6.548 and loss : 62.43256 \n",
      "Epoch 9, w : 6.915 and loss : 45.10752 \n",
      "Epoch 10, w : 7.228 and loss : 32.59019 \n",
      "Epoch 11, w : 7.494 and loss : 23.54642 \n",
      "Epoch 12, w : 7.720 and loss : 17.01229 \n",
      "Epoch 13, w : 7.912 and loss : 12.29137 \n",
      "Epoch 14, w : 8.075 and loss : 8.88052 \n",
      "Epoch 15, w : 8.214 and loss : 6.41617 \n",
      "Epoch 16, w : 8.332 and loss : 4.63569 \n",
      "Epoch 17, w : 8.432 and loss : 3.34928 \n",
      "Epoch 18, w : 8.517 and loss : 2.41986 \n",
      "Epoch 19, w : 8.590 and loss : 1.74835 \n",
      "Epoch 20, w : 8.651 and loss : 1.26318 \n",
      "Epoch 21, w : 8.703 and loss : 0.91264 \n",
      "Epoch 22, w : 8.748 and loss : 0.65939 \n",
      "Epoch 23, w : 8.786 and loss : 0.47641 \n",
      "Epoch 24, w : 8.818 and loss : 0.34420 \n",
      "Epoch 25, w : 8.845 and loss : 0.24869 \n",
      "Epoch 26, w : 8.868 and loss : 0.17968 \n",
      "Epoch 27, w : 8.888 and loss : 0.12982 \n",
      "Epoch 28, w : 8.905 and loss : 0.09379 \n",
      "Epoch 29, w : 8.919 and loss : 0.06777 \n",
      "Epoch 30, w : 8.931 and loss : 0.04896 \n",
      "Epoch 31, w : 8.942 and loss : 0.03537 \n",
      "Epoch 32, w : 8.950 and loss : 0.02556 \n",
      "Epoch 33, w : 8.958 and loss : 0.01847 \n",
      "Epoch 34, w : 8.964 and loss : 0.01334 \n",
      "Epoch 35, w : 8.970 and loss : 0.00964 \n",
      "Epoch 36, w : 8.974 and loss : 0.00696 \n",
      "Epoch 37, w : 8.978 and loss : 0.00503 \n",
      "Epoch 38, w : 8.981 and loss : 0.00364 \n",
      "Epoch 39, w : 8.984 and loss : 0.00263 \n",
      "Epoch 40, w : 8.986 and loss : 0.00190 \n",
      "Epoch 41, w : 8.989 and loss : 0.00137 \n",
      "Epoch 42, w : 8.990 and loss : 0.00099 \n",
      "Epoch 43, w : 8.992 and loss : 0.00072 \n",
      "Epoch 44, w : 8.993 and loss : 0.00052 \n",
      "Epoch 45, w : 8.994 and loss : 0.00037 \n",
      "Epoch 46, w : 8.995 and loss : 0.00027 \n",
      "Epoch 47, w : 8.996 and loss : 0.00019 \n",
      "Epoch 48, w : 8.996 and loss : 0.00014 \n",
      "Epoch 49, w : 8.997 and loss : 0.00010 \n",
      "Epoch 50, w : 8.997 and loss : 0.00007 \n",
      "Epoch 51, w : 8.998 and loss : 0.00005 \n",
      "Epoch 52, w : 8.998 and loss : 0.00004 \n",
      "Epoch 53, w : 8.998 and loss : 0.00003 \n",
      "Epoch 54, w : 8.999 and loss : 0.00002 \n",
      "Epoch 55, w : 8.999 and loss : 0.00001 \n",
      "Epoch 56, w : 8.999 and loss : 0.00001 \n",
      "Epoch 57, w : 8.999 and loss : 0.00001 \n",
      "Epoch 58, w : 8.999 and loss : 0.00001 \n",
      "Epoch 59, w : 8.999 and loss : 0.00000 \n",
      "Epoch 60, w : 8.999 and loss : 0.00000 \n",
      "Epoch 61, w : 9.000 and loss : 0.00000 \n",
      "Epoch 62, w : 9.000 and loss : 0.00000 \n",
      "Epoch 63, w : 9.000 and loss : 0.00000 \n",
      "Epoch 64, w : 9.000 and loss : 0.00000 \n",
      "Epoch 65, w : 9.000 and loss : 0.00000 \n",
      "Epoch 66, w : 9.000 and loss : 0.00000 \n",
      "Epoch 67, w : 9.000 and loss : 0.00000 \n",
      "Epoch 68, w : 9.000 and loss : 0.00000 \n",
      "Epoch 69, w : 9.000 and loss : 0.00000 \n",
      "Epoch 70, w : 9.000 and loss : 0.00000 \n",
      "Epoch 71, w : 9.000 and loss : 0.00000 \n",
      "Epoch 72, w : 9.000 and loss : 0.00000 \n",
      "Epoch 73, w : 9.000 and loss : 0.00000 \n",
      "Epoch 74, w : 9.000 and loss : 0.00000 \n",
      "Epoch 75, w : 9.000 and loss : 0.00000 \n",
      "Epoch 76, w : 9.000 and loss : 0.00000 \n",
      "Epoch 77, w : 9.000 and loss : 0.00000 \n",
      "Epoch 78, w : 9.000 and loss : 0.00000 \n",
      "Epoch 79, w : 9.000 and loss : 0.00000 \n",
      "Epoch 80, w : 9.000 and loss : 0.00000 \n",
      "Epoch 81, w : 9.000 and loss : 0.00000 \n",
      "Epoch 82, w : 9.000 and loss : 0.00000 \n",
      "Epoch 83, w : 9.000 and loss : 0.00000 \n",
      "Epoch 84, w : 9.000 and loss : 0.00000 \n",
      "Epoch 85, w : 9.000 and loss : 0.00000 \n",
      "Epoch 86, w : 9.000 and loss : 0.00000 \n",
      "Epoch 87, w : 9.000 and loss : 0.00000 \n",
      "Epoch 88, w : 9.000 and loss : 0.00000 \n",
      "Epoch 89, w : 9.000 and loss : 0.00000 \n",
      "Epoch 90, w : 9.000 and loss : 0.00000 \n",
      "Epoch 91, w : 9.000 and loss : 0.00000 \n",
      "Epoch 92, w : 9.000 and loss : 0.00000 \n",
      "Epoch 93, w : 9.000 and loss : 0.00000 \n",
      "Epoch 94, w : 9.000 and loss : 0.00000 \n",
      "Epoch 95, w : 9.000 and loss : 0.00000 \n",
      "Epoch 96, w : 9.000 and loss : 0.00000 \n",
      "Epoch 97, w : 9.000 and loss : 0.00000 \n",
      "Epoch 98, w : 9.000 and loss : 0.00000 \n",
      "Epoch 99, w : 9.000 and loss : 0.00000 \n",
      "Epoch 100, w : 9.000 and loss : 0.00000 \n",
      "Prediction after training f(5): 45.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_iters):\n",
    "    y_pred=forward(X)\n",
    "    l=loss(Y,y_pred)\n",
    "\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f'Epoch {epoch+1}, w : {w:.3f} and loss : {l:.5f} ')\n",
    "print(f'Prediction after training f(5): {forward(5):.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47c3d642174270f224528408ce260e326450f5d01584567606deb2c7196ef238"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
